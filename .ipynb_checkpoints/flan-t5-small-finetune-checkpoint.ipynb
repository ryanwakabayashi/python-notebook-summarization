{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T21:05:43.875254900Z",
     "start_time": "2024-05-09T21:05:39.914227300Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TrainingArguments, pipeline, logging, T5ForConditionalGeneration, T5Tokenizer, AutoModelForSeq2SeqLM\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "872506e900096fb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T21:05:44.987965100Z",
     "start_time": "2024-05-09T21:05:43.877256600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"google/flan-t5-small\"\n",
    "\n",
    "quant_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16, bnb_4bit_use_double_quant=False)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME, device_map=\"auto\", quantization_config=quant_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2956fb5287094792",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T21:05:44.993191900Z",
     "start_time": "2024-05-09T21:05:44.988965600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "peft_params = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_2_SEQ_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e629aeca3b66deb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T21:05:45.044171500Z",
     "start_time": "2024-05-09T21:05:44.991192Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2,752,512 || all params: 79,713,664 || trainable%: 3.4529989739274813\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model, peft_params)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e77d4e1d4bf563d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T21:05:45.110963800Z",
     "start_time": "2024-05-09T21:05:45.043173500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>notebook_data</th>\n",
       "      <th>line_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>1000910.ipynb</td>\n",
       "      <td># This Python 3 environment comes with many he...</td>\n",
       "      <td>14</td>\n",
       "      <td>698</td>\n",
       "      <td>Summarize the following code in two to three s...</td>\n",
       "      <td>The code imports various libraries, including ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>1006787.ipynb</td>\n",
       "      <td># This R environment comes with all of CRAN pr...</td>\n",
       "      <td>18</td>\n",
       "      <td>923</td>\n",
       "      <td>Summarize the following code in two to three s...</td>\n",
       "      <td>The code intends to load necessary packages fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1718</th>\n",
       "      <td>1011203.ipynb</td>\n",
       "      <td># This R environment comes with all of CRAN pr...</td>\n",
       "      <td>18</td>\n",
       "      <td>1227</td>\n",
       "      <td>Summarize the following code in two to three s...</td>\n",
       "      <td>The code intends to load and analyze a dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>1006791.ipynb</td>\n",
       "      <td># This R environment comes with all of CRAN pr...</td>\n",
       "      <td>58</td>\n",
       "      <td>2139</td>\n",
       "      <td>Summarize the following code in two to three s...</td>\n",
       "      <td>The code intends to explore and preprocess a c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>1008495.ipynb</td>\n",
       "      <td>from sklearn.ensemble import RandomForestRegre...</td>\n",
       "      <td>73</td>\n",
       "      <td>2750</td>\n",
       "      <td>Summarize the following code in two to three s...</td>\n",
       "      <td>The code is building a random forest regressio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>1007446.ipynb</td>\n",
       "      <td>- [IBU][1]: The International Bittering Units...</td>\n",
       "      <td>61</td>\n",
       "      <td>3410</td>\n",
       "      <td>Summarize the following code in two to three s...</td>\n",
       "      <td>The code aims to analyze the relationship betw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>1007799.ipynb</td>\n",
       "      <td># This Python 3 environment comes with many he...</td>\n",
       "      <td>27</td>\n",
       "      <td>1091</td>\n",
       "      <td>Summarize the following code in two to three s...</td>\n",
       "      <td>The code intends to train a Support Vector Mac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>1008781.ipynb</td>\n",
       "      <td>import pandas as pd\\nimport seaborn as sns\\nim...</td>\n",
       "      <td>25</td>\n",
       "      <td>1310</td>\n",
       "      <td>Summarize the following code in two to three s...</td>\n",
       "      <td>The code intends to analyze and visualize glob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>1005684.ipynb</td>\n",
       "      <td>## This notebook demos Python data visualizati...</td>\n",
       "      <td>91</td>\n",
       "      <td>5436</td>\n",
       "      <td>Summarize the following code in two to three s...</td>\n",
       "      <td>The code intends to demonstrate various data v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3174</th>\n",
       "      <td>1023280.ipynb</td>\n",
       "      <td># This Python 3 environment comes with many he...</td>\n",
       "      <td>55</td>\n",
       "      <td>2197</td>\n",
       "      <td>Summarize the following code in two to three s...</td>\n",
       "      <td>The code intends to process and manipulate a d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2800 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename                                      notebook_data  \\\n",
       "162   1000910.ipynb  # This Python 3 environment comes with many he...   \n",
       "1001  1006787.ipynb  # This R environment comes with all of CRAN pr...   \n",
       "1718  1011203.ipynb  # This R environment comes with all of CRAN pr...   \n",
       "1003  1006791.ipynb  # This R environment comes with all of CRAN pr...   \n",
       "1233  1008495.ipynb  from sklearn.ensemble import RandomForestRegre...   \n",
       "...             ...                                                ...   \n",
       "1095  1007446.ipynb   - [IBU][1]: The International Bittering Units...   \n",
       "1130  1007799.ipynb  # This Python 3 environment comes with many he...   \n",
       "1294  1008781.ipynb  import pandas as pd\\nimport seaborn as sns\\nim...   \n",
       "860   1005684.ipynb  ## This notebook demos Python data visualizati...   \n",
       "3174  1023280.ipynb  # This Python 3 environment comes with many he...   \n",
       "\n",
       "      line_count  char_count  \\\n",
       "162           14         698   \n",
       "1001          18         923   \n",
       "1718          18        1227   \n",
       "1003          58        2139   \n",
       "1233          73        2750   \n",
       "...          ...         ...   \n",
       "1095          61        3410   \n",
       "1130          27        1091   \n",
       "1294          25        1310   \n",
       "860           91        5436   \n",
       "3174          55        2197   \n",
       "\n",
       "                                               question  \\\n",
       "162   Summarize the following code in two to three s...   \n",
       "1001  Summarize the following code in two to three s...   \n",
       "1718  Summarize the following code in two to three s...   \n",
       "1003  Summarize the following code in two to three s...   \n",
       "1233  Summarize the following code in two to three s...   \n",
       "...                                                 ...   \n",
       "1095  Summarize the following code in two to three s...   \n",
       "1130  Summarize the following code in two to three s...   \n",
       "1294  Summarize the following code in two to three s...   \n",
       "860   Summarize the following code in two to three s...   \n",
       "3174  Summarize the following code in two to three s...   \n",
       "\n",
       "                                                 answer  \n",
       "162   The code imports various libraries, including ...  \n",
       "1001  The code intends to load necessary packages fo...  \n",
       "1718  The code intends to load and analyze a dataset...  \n",
       "1003  The code intends to explore and preprocess a c...  \n",
       "1233  The code is building a random forest regressio...  \n",
       "...                                                 ...  \n",
       "1095  The code aims to analyze the relationship betw...  \n",
       "1130  The code intends to train a Support Vector Mac...  \n",
       "1294  The code intends to analyze and visualize glob...  \n",
       "860   The code intends to demonstrate various data v...  \n",
       "3174  The code intends to process and manipulate a d...  \n",
       "\n",
       "[2800 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "llama_3_data = pd.read_parquet(\"data/data_cleaned.parquet\", engine=\"pyarrow\")\n",
    "train_df, test_df = train_test_split(llama_3_data, test_size=0.2, random_state=42)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0c5c79b59924a6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T21:05:45.218680300Z",
     "start_time": "2024-05-09T21:05:45.108454400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['filename', 'notebook_data', 'line_count', 'char_count', 'question', 'answer'],\n",
       "        num_rows: 2800\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['filename', 'notebook_data', 'line_count', 'char_count', 'question', 'answer'],\n",
       "        num_rows: 700\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "train_dataset = Dataset.from_dict(train_df)\n",
    "test_dataset = Dataset.from_dict(test_df)\n",
    "dataset = DatasetDict({\"train\": train_dataset, \"test\": test_dataset})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c19b7bc1f1b77fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T21:05:47.135990400Z",
     "start_time": "2024-05-09T21:05:45.201604400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "759683ea5b794171b74029be1cb11694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c77652281fb4ef599ef67988c23e797",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/700 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(example):\n",
    "    example['input_ids'] = tokenizer(example['question'], padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
    "    example['labels'] = tokenizer(example[\"answer\"], padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
    "    \n",
    "    return example\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb8ad98368f83118",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T21:05:47.140725100Z",
     "start_time": "2024-05-09T21:05:47.138107800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['filename', 'notebook_data', 'line_count', 'char_count', 'question', 'answer', 'input_ids', 'labels'],\n",
       "        num_rows: 2800\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['filename', 'notebook_data', 'line_count', 'char_count', 'question', 'answer', 'input_ids', 'labels'],\n",
       "        num_rows: 700\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a998b4aa58d6029",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T21:05:47.526161100Z",
     "start_time": "2024-05-09T21:05:47.141261300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37, 1081, 4830, 7, 796, 12256, 6, 379, 1174, 51, 345, 63, 11, 28248, 7, 6, 21, 331, 3026, 11, 1693, 5, 94, 92, 4830, 7, 8, 1510, 7, 9434, 291, 29, 3595, 6, 15495, 24, 8, 1081, 8286, 7, 12, 1912, 1437, 1036, 4145, 5, 37, 1081, 3475, 12, 36, 356, 95, 12, 2174, 331, 2073, 16, 8, 96, 5, 5, 87, 77, 2562, 87, 121, 8174, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_dataset['train']['labels'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "304f4a885843f2df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T21:05:47.529389100Z",
     "start_time": "2024-05-09T21:05:47.525160900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "tokenized_dataset = tokenized_dataset.remove_columns(dataset[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbbdfe430c5ec624",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T21:05:47.598313900Z",
     "start_time": "2024-05-09T21:05:47.530388900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'labels'],\n",
       "        num_rows: 2800\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'labels'],\n",
       "        num_rows: 700\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e190f77bb3c099",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T21:08:37.735939700Z",
     "start_time": "2024-05-09T21:08:37.685655900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    # disable_tqdm=False,\n",
    "    # evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    num_train_epochs=3\n",
    ")\n",
    "\n",
    "def formatting_func(example):\n",
    "    text = f\"### Question: {example['question']}\\n ### Answer: {example['answer']}\"\n",
    "    # text = f\"Question: {example['question']}\\nAnswer: {example['answer']}\"\n",
    "    return text\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    peft_config=peft_params,\n",
    "    # dataset_text_field=\"text\",\n",
    "    formatting_func=formatting_func,\n",
    "    max_seq_length=1024,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    packing=False,\n",
    "    # packing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91d6db50db38a033",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T21:09:56.607735600Z",
     "start_time": "2024-05-09T21:08:38.136298100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [525/525 01:17, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.657000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=525, training_loss=0.6491829427083333, metrics={'train_runtime': 78.5502, 'train_samples_per_second': 106.938, 'train_steps_per_second': 6.684, 'total_flos': 1632508261171200.0, 'train_loss': 0.6491829427083333, 'epoch': 3.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7790960b11490e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T21:07:07.666147700Z",
     "start_time": "2024-05-09T21:07:07.524820700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('flan-t5-small-fine-tuned\\\\tokenizer_config.json',\n",
       " 'flan-t5-small-fine-tuned\\\\special_tokens_map.json',\n",
       " 'flan-t5-small-fine-tuned\\\\spiece.model',\n",
       " 'flan-t5-small-fine-tuned\\\\added_tokens.json',\n",
       " 'flan-t5-small-fine-tuned\\\\tokenizer.json')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = \"flan-t5-small-fine-tuned\"\n",
    "\n",
    "trainer.model.save_pretrained(new_model)\n",
    "trainer.tokenizer.save_pretrained(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dc54ac5f22a079",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T21:07:07.669304300Z",
     "start_time": "2024-05-09T21:07:07.666793700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
