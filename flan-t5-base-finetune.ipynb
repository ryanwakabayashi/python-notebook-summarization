{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-09T19:58:10.134832300Z",
     "start_time": "2024-05-09T19:58:06.020269200Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TrainingArguments, pipeline, logging, T5ForConditionalGeneration, T5Tokenizer, AutoModelForSeq2SeqLM\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "MODEL_NAME = \"google/flan-t5-base\"\n",
    "\n",
    "quant_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16, bnb_4bit_use_double_quant=False)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME, device_map=\"auto\", quantization_config=quant_config)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T19:58:11.669638500Z",
     "start_time": "2024-05-09T19:58:10.134832300Z"
    }
   },
   "id": "872506e900096fb3",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "peft_params = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_2_SEQ_LM\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T19:58:11.673497800Z",
     "start_time": "2024-05-09T19:58:11.670988100Z"
    }
   },
   "id": "2956fb5287094792",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 7,077,888 || all params: 254,655,744 || trainable%: 2.779394601050114\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model, peft_params)\n",
    "model.print_trainable_parameters()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T19:58:11.768439100Z",
     "start_time": "2024-05-09T19:58:11.672498200Z"
    }
   },
   "id": "2e629aeca3b66deb",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "           filename                                      notebook_data  \\\n162   1000910.ipynb  # This Python 3 environment comes with many he...   \n1001  1006787.ipynb  # This R environment comes with all of CRAN pr...   \n1718  1011203.ipynb  # This R environment comes with all of CRAN pr...   \n1003  1006791.ipynb  # This R environment comes with all of CRAN pr...   \n1233  1008495.ipynb  from sklearn.ensemble import RandomForestRegre...   \n...             ...                                                ...   \n1095  1007446.ipynb   - [IBU][1]: The International Bittering Units...   \n1130  1007799.ipynb  # This Python 3 environment comes with many he...   \n1294  1008781.ipynb  import pandas as pd\\nimport seaborn as sns\\nim...   \n860   1005684.ipynb  ## This notebook demos Python data visualizati...   \n3174  1023280.ipynb  # This Python 3 environment comes with many he...   \n\n      line_count  char_count  \\\n162           14         698   \n1001          18         923   \n1718          18        1227   \n1003          58        2139   \n1233          73        2750   \n...          ...         ...   \n1095          61        3410   \n1130          27        1091   \n1294          25        1310   \n860           91        5436   \n3174          55        2197   \n\n                                               question  \\\n162   Summarize the following code in two to three s...   \n1001  Summarize the following code in two to three s...   \n1718  Summarize the following code in two to three s...   \n1003  Summarize the following code in two to three s...   \n1233  Summarize the following code in two to three s...   \n...                                                 ...   \n1095  Summarize the following code in two to three s...   \n1130  Summarize the following code in two to three s...   \n1294  Summarize the following code in two to three s...   \n860   Summarize the following code in two to three s...   \n3174  Summarize the following code in two to three s...   \n\n                                                 answer  \n162   The code imports various libraries, including ...  \n1001  The code intends to load necessary packages fo...  \n1718  The code intends to load and analyze a dataset...  \n1003  The code intends to explore and preprocess a c...  \n1233  The code is building a random forest regressio...  \n...                                                 ...  \n1095  The code aims to analyze the relationship betw...  \n1130  The code intends to train a Support Vector Mac...  \n1294  The code intends to analyze and visualize glob...  \n860   The code intends to demonstrate various data v...  \n3174  The code intends to process and manipulate a d...  \n\n[2800 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>notebook_data</th>\n      <th>line_count</th>\n      <th>char_count</th>\n      <th>question</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>162</th>\n      <td>1000910.ipynb</td>\n      <td># This Python 3 environment comes with many he...</td>\n      <td>14</td>\n      <td>698</td>\n      <td>Summarize the following code in two to three s...</td>\n      <td>The code imports various libraries, including ...</td>\n    </tr>\n    <tr>\n      <th>1001</th>\n      <td>1006787.ipynb</td>\n      <td># This R environment comes with all of CRAN pr...</td>\n      <td>18</td>\n      <td>923</td>\n      <td>Summarize the following code in two to three s...</td>\n      <td>The code intends to load necessary packages fo...</td>\n    </tr>\n    <tr>\n      <th>1718</th>\n      <td>1011203.ipynb</td>\n      <td># This R environment comes with all of CRAN pr...</td>\n      <td>18</td>\n      <td>1227</td>\n      <td>Summarize the following code in two to three s...</td>\n      <td>The code intends to load and analyze a dataset...</td>\n    </tr>\n    <tr>\n      <th>1003</th>\n      <td>1006791.ipynb</td>\n      <td># This R environment comes with all of CRAN pr...</td>\n      <td>58</td>\n      <td>2139</td>\n      <td>Summarize the following code in two to three s...</td>\n      <td>The code intends to explore and preprocess a c...</td>\n    </tr>\n    <tr>\n      <th>1233</th>\n      <td>1008495.ipynb</td>\n      <td>from sklearn.ensemble import RandomForestRegre...</td>\n      <td>73</td>\n      <td>2750</td>\n      <td>Summarize the following code in two to three s...</td>\n      <td>The code is building a random forest regressio...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1095</th>\n      <td>1007446.ipynb</td>\n      <td>- [IBU][1]: The International Bittering Units...</td>\n      <td>61</td>\n      <td>3410</td>\n      <td>Summarize the following code in two to three s...</td>\n      <td>The code aims to analyze the relationship betw...</td>\n    </tr>\n    <tr>\n      <th>1130</th>\n      <td>1007799.ipynb</td>\n      <td># This Python 3 environment comes with many he...</td>\n      <td>27</td>\n      <td>1091</td>\n      <td>Summarize the following code in two to three s...</td>\n      <td>The code intends to train a Support Vector Mac...</td>\n    </tr>\n    <tr>\n      <th>1294</th>\n      <td>1008781.ipynb</td>\n      <td>import pandas as pd\\nimport seaborn as sns\\nim...</td>\n      <td>25</td>\n      <td>1310</td>\n      <td>Summarize the following code in two to three s...</td>\n      <td>The code intends to analyze and visualize glob...</td>\n    </tr>\n    <tr>\n      <th>860</th>\n      <td>1005684.ipynb</td>\n      <td>## This notebook demos Python data visualizati...</td>\n      <td>91</td>\n      <td>5436</td>\n      <td>Summarize the following code in two to three s...</td>\n      <td>The code intends to demonstrate various data v...</td>\n    </tr>\n    <tr>\n      <th>3174</th>\n      <td>1023280.ipynb</td>\n      <td># This Python 3 environment comes with many he...</td>\n      <td>55</td>\n      <td>2197</td>\n      <td>Summarize the following code in two to three s...</td>\n      <td>The code intends to process and manipulate a d...</td>\n    </tr>\n  </tbody>\n</table>\n<p>2800 rows Ã— 6 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "llama_3_data = pd.read_parquet(\"data/data_cleaned.parquet\", engine=\"pyarrow\")\n",
    "train_df, test_df = train_test_split(llama_3_data, test_size=0.2, random_state=42)\n",
    "train_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T19:58:11.857448Z",
     "start_time": "2024-05-09T19:58:11.768439100Z"
    }
   },
   "id": "7e77d4e1d4bf563d",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['filename', 'notebook_data', 'line_count', 'char_count', 'question', 'answer'],\n        num_rows: 2800\n    })\n    test: Dataset({\n        features: ['filename', 'notebook_data', 'line_count', 'char_count', 'question', 'answer'],\n        num_rows: 700\n    })\n})"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "train_dataset = Dataset.from_dict(train_df)\n",
    "test_dataset = Dataset.from_dict(test_df)\n",
    "dataset = DatasetDict({\"train\": train_dataset, \"test\": test_dataset})\n",
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T19:58:11.975112400Z",
     "start_time": "2024-05-09T19:58:11.871952700Z"
    }
   },
   "id": "b0c5c79b59924a6b",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/2800 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8370faf29ac44463b5cc873e448637a1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/700 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "50338cc3617e4c36846d66e5d7259080"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(example):\n",
    "    example['input_ids'] = tokenizer(example['question'], padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
    "    example['labels'] = tokenizer(example[\"answer\"], padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
    "    \n",
    "    return example\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T19:58:13.780236Z",
     "start_time": "2024-05-09T19:58:11.951092200Z"
    }
   },
   "id": "c19b7bc1f1b77fd",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['filename', 'notebook_data', 'line_count', 'char_count', 'question', 'answer', 'input_ids', 'labels'],\n        num_rows: 2800\n    })\n    test: Dataset({\n        features: ['filename', 'notebook_data', 'line_count', 'char_count', 'question', 'answer', 'input_ids', 'labels'],\n        num_rows: 700\n    })\n})"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T19:58:13.784994800Z",
     "start_time": "2024-05-09T19:58:13.781235800Z"
    }
   },
   "id": "eb8ad98368f83118",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37, 1081, 4830, 7, 796, 12256, 6, 379, 1174, 51, 345, 63, 11, 28248, 7, 6, 21, 331, 3026, 11, 1693, 5, 94, 92, 4830, 7, 8, 1510, 7, 9434, 291, 29, 3595, 6, 15495, 24, 8, 1081, 8286, 7, 12, 1912, 1437, 1036, 4145, 5, 37, 1081, 3475, 12, 36, 356, 95, 12, 2174, 331, 2073, 16, 8, 96, 5, 5, 87, 77, 2562, 87, 121, 8174, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_dataset['train']['labels'][0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T19:58:14.155583700Z",
     "start_time": "2024-05-09T19:58:13.785995600Z"
    }
   },
   "id": "4a998b4aa58d6029",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tokenized_dataset = tokenized_dataset.remove_columns(dataset[\"train\"].column_names)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T19:58:14.156586100Z",
     "start_time": "2024-05-09T19:58:14.152583500Z"
    }
   },
   "id": "304f4a885843f2df",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'labels'],\n        num_rows: 2800\n    })\n    test: Dataset({\n        features: ['input_ids', 'labels'],\n        num_rows: 700\n    })\n})"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T19:58:14.161589900Z",
     "start_time": "2024-05-09T19:58:14.157090600Z"
    }
   },
   "id": "dbbdfe430c5ec624",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    # disable_tqdm=False,\n",
    "    # evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    num_train_epochs=3\n",
    ")\n",
    "\n",
    "def formatting_func(example):\n",
    "    text = f\"### Question: {example['question']}\\n ### Answer: {example['answer']}\"\n",
    "    # text = f\"Question: {example['question']}\\nAnswer: {example['answer']}\"\n",
    "    return text\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    peft_config=peft_params,\n",
    "    # dataset_text_field=\"text\",\n",
    "    formatting_func=formatting_func,\n",
    "    max_seq_length=1024,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    packing=False,\n",
    "    # packing=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T19:58:14.288119100Z",
     "start_time": "2024-05-09T19:58:14.162400500Z"
    }
   },
   "id": "4e190f77bb3c099",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  2/525 : < :, Epoch 0.01/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "TrainOutput(global_step=525, training_loss=0.35078078497023807, metrics={'train_runtime': 3933.7726, 'train_samples_per_second': 2.135, 'train_steps_per_second': 0.133, 'total_flos': 5934605244825600.0, 'train_loss': 0.35078078497023807, 'epoch': 3.0})"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T21:03:48.190434800Z",
     "start_time": "2024-05-09T19:58:14.392808300Z"
    }
   },
   "id": "91d6db50db38a033",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "('flan-t5-base-fine-tuned\\\\tokenizer_config.json',\n 'flan-t5-base-fine-tuned\\\\special_tokens_map.json',\n 'flan-t5-base-fine-tuned\\\\spiece.model',\n 'flan-t5-base-fine-tuned\\\\added_tokens.json',\n 'flan-t5-base-fine-tuned\\\\tokenizer.json')"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = \"flan-t5-base-fine-tuned\"\n",
    "\n",
    "trainer.model.save_pretrained(new_model)\n",
    "trainer.tokenizer.save_pretrained(new_model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T21:03:48.384063100Z",
     "start_time": "2024-05-09T21:03:48.192434600Z"
    }
   },
   "id": "e7790960b11490e9",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T21:03:48.386941700Z",
     "start_time": "2024-05-09T21:03:48.385433900Z"
    }
   },
   "id": "f0dc54ac5f22a079",
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
